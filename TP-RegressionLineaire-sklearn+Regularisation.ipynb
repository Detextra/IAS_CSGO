{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP -- Regression Linéaire -- sklearn + Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarque: les parties sont indépendantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 - mise en pratique\n",
    "\n",
    "Puisqu'on n'a jamais fait de régression linéaire en TD, et qu'on en a parlé, mais assez rapidement, en cours, on commence par une illustration de ce que peut faire la régression linéaire, sur un cas concret:\n",
    "\n",
    "C'est le fameux *boston house market* data set: \n",
    "\n",
    "https://www.kaggle.com/vikrishnan/boston-house-prices/ \n",
    "\n",
    "On s'inspire assez amplement de la solution de l'autrice du dataset, au moins pour ce qui est du chargement des données:\n",
    "\n",
    "https://www.kaggle.com/vikrishnan/house-sales-price-using-regression\n",
    "\n",
    "En gros, on a des données sur différents quartiers de Boston, et pour chaque quartier, on a le prix médian des maisons (ou appartements). On cherche à comprendre comment certains facteurs du voisinage déterminent le prix des maisons d'un quartier. Ou bien plus simplement, dans le cadre de ce DM, on se contente de tenter de prédire le prix des maisons en fonction des données fournies en entrée.\n",
    "\n",
    "Comme d'habitude, on a $N$ points dans l'ensemble d'entraînement, chaque point de donnée est en dimension $D$, et les labels à prédire sont des valeurs continues, $y_n\\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1.0 - petite démo de statistiques descriptives\n",
    "\n",
    "Ici, vous n'avez rien à faire, juste à lire ce qu'on vous présente (ce sera bien pratique pour les projets!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chargement des données\n",
    "filename = \"TP-RegressionLineaire-data-partie1-housing.csv\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataset = pd.read_csv(filename, delim_whitespace=True, names=names)\n",
    "dataset.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# on consulte les types ds données:\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "'RM' is the average number of rooms among homes in the neighborhood.\n",
    "\n",
    "'LSTAT' is the percentage of homeowners in the neighborhood considered \"lower class\" (working poor).\n",
    "\n",
    "'PTRATIO' is the ratio of students to teachers in primary and secondary schools in the neighborhood.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# aperçu des stats de chaque colonne\n",
    "pd.set_option('precision', 1)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualizations\n",
    "\n",
    "# histograms\n",
    "dataset.hist(bins=10,figsize=(12,10),grid=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on calcule les corréaltions entre colonnes (coeff. de correlation de Pearson)\n",
    "pd.set_option('precision', 2)\n",
    "dataset.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encore une visu des corrélations (ça peut etre bienlong à executer)\n",
    "# import seaborn as sns\n",
    "# sns.pairplot(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On accède aux noms des colonnes ainsi:\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## les colonnes (sauf la dernière) correspondent aux variables explicatives du prix (features)\n",
    "features = dataset.columns[:-1]\n",
    "\n",
    "# la derniere colonne, MEDV, correspond à la valeur médiane (Median Value) des maisons dans un quartier\n",
    "label = dataset.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on convertit les tableaux pandas en tabeaux numpy\n",
    "X = dataset[features].values\n",
    "Y = dataset[label].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1.1 - entrainement, validation, test\n",
    "\n",
    "**C'est à vous de jouer !**\n",
    "\n",
    "Il va vous falloir: (il y a des bouts de codes donnés, plus bas)\n",
    "- Séparer les données en entrainement/test (30% pour le test, 70% l'entrainement)\n",
    "- Utiliser le modèle d'apprentissage `sklearn.linear_model.Ridge`, qui correspond à la regression linéaire avec régularisation de type Ridge, c.a.d. de type $\\alpha ||\\vec{w}||_2^2$. Ce modèle dépend d'un hyper-paramètre $\\alpha$ `alpha`, qui correspond au niveau de régularisation  (souvent noté $\\lambda$ (lambda) en cours).\n",
    "- Appliquer la cross-validation sur l'ensemble dit \"d'entrainement\" (les 70%). Utilisez 5 \"plis\" (*fold*). Cela va permettre de trouver la meilleure valeur possible pour l'hyper-paramètre `alpha`.\n",
    "- Une fois la valeur idéale de $\\alpha=\\alpha^*$ trouvée, entrainer le modèle sur l'ensemble de l'ensemble d'entrainement (la totalité des 70%) et mesurer le score sur l'ensemble de test (et tant qu'à faire, aussi sur l'ensemble d'entrainement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "- Séparer les données en entrainement/test (30% pour le test, 70% l'entrainement)\n",
    "\n",
    "On fait le fameux train-test split (séparation des données en ensemble d'entrainement+ensemble de test)\n",
    "\n",
    "Indice: utilser, si vous le souhaitez, la méthode  `sklearn.model_selection.train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = ??\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test =  ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je suis concerné aussi, mais je pense que c'est jouable dans la mesure où ce qui compte c'est l'évolution-----\n",
    "\n",
    "- Utiliser le modèle d'apprentissage `sklearn.linear_model.Ridge`, qui correspond à la regression linéaire avec régularisation de type Ridge, c.a.d. de type $\\alpha ||\\vec{w}||_2^2$. Ce modèle dépend d'un hyper-paramètre $\\alpha$ `alpha`, qui correspond au niveau de régularisation  (souvent noté $\\lambda$ (lambda) en cours).\n",
    "\n",
    "- Concrètement:\n",
    "    - utiliser `np.logspace` pour générer des valeurs de alpha à explorer. Par exemple, ` np.logspace(-5,-2, num=4)` génère des nombres de 10⁻⁵ à 10⁻² (ce n'est pas forcément la bonne plage de valeurs, à vous de voir !)\n",
    "    - définir un modèle: ce sera `sklearn.linear_model.Ridge(alpha=alpha)`\n",
    "    - Définir une découpe en plis. On va utilsier `sklearn.model_selection.cross_val_score`. Il y a 2 arguments optionels importants: \n",
    "        - `cv=...` Là il faut passer un objet du genre de `sklearn.model_selection.KFold(n_splits=num_folds)` en entrée.\n",
    "        - `scoring=...` Là il faut passer une méthode de scoring. On va utiliser l'erreur quadratique moyenne, `'neg_mean_squared_error'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-5,-2, num=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple de definition d'un modèle\n",
    "alpha=3\n",
    "monModele =  ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "kfold = ??\n",
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monScoring = 'neg_mean_squared_error' # (RMS=Root Mean Squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour choisir parmi les possiblités standard de scoring, on peut aller voir:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alpha_values:\n",
    "    monModele = ??\n",
    "    cv_results = sklearn.model_selection.cross_val_score(??,??,??, cv=??, scoring=??)\n",
    "    msg = \"%s %f, erreur quad. moyenne: %f +/- (%f)\" % (\"regression lineaire:, alpha=\",alpha, -cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------- \n",
    "\n",
    "- Une fois la valeur idéale de $\\alpha=\\alpha^*$ trouvée, entrainer le modèle sur l'ensemble de l'ensemble d'entrainement (la totalité des 70%) et mesurer le score sur l'ensemble de test (et tant qu'à faire, aussi sur l'ensemble d'entrainement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_etoile = ??\n",
    "monModele = ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monModele.fit(X_train, Y_train)\n",
    "Y_train_pred = monModele.predict(X_train)\n",
    "print(\"train error\", sklearn.metrics.mean_squared_error(Y_train_pred, Y_train))\n",
    "\n",
    "Y_test_pred = monModele.predict(X_test)\n",
    "print(\"test error\", sklearn.metrics.mean_squared_error(Y_test_pred, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aide:\n",
    "\n",
    "le résultat attendu est de l'ordre de :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train error 21.239136894641618\n",
    "test error 25.84300641516924"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1.2 visualisation et exploitation des résultats \n",
    "\n",
    "Ici on va se limiter à très peu de choses:\n",
    "    - comparer les Y_train_pred aux Y_train\n",
    "    - comparer les Y_test_pred aux Y_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin= min(Y_train.min(), Y_train_pred.min() )-1\n",
    "xmax= max(Y_train.max(), Y_train_pred.max() )+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "plt.scatter(??, ??, marker='x', label='train')\n",
    "plt.scatter(??, ??, marker='+', label='test')\n",
    "plt.plot([xmin,xmax], [xmin,xmax], lw=3, color='k', ls='--') ## droite separatrice d'equation x2=x1\n",
    "\n",
    "# ?labe -> xlabel ou ylabel: a vous de voir\n",
    "plt.?label('verite terrain')\n",
    "plt.?label('prediction du modele') \n",
    "plt.legend()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect('equal') # on veut une figure carrée et pas allongée.\n",
    "# plt.xlim([xmin,xmax])\n",
    "# plt.ylim([xmin,xmax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

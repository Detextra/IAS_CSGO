{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1147fb-b8f4-4fd0-873f-f2808789fd30",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 39] Directory not empty: 'prices/.ipynb_checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5916/3031616982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'datetime64[ns]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prices/.ipynb_checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0mdirct_cn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prices'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0mdirct_cn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 39] Directory not empty: 'prices/.ipynb_checkpoints'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import *\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import os\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "plt.ion()\n",
    "\n",
    "def pearson(X,Y):\n",
    "    try:\n",
    "        mX = sum(X)/len(X) # mean of X and Y lists\n",
    "        mY = sum(Y)/len(Y)\n",
    "    \n",
    "        cov = sum((a - mX) * (b - mY) for (a,b) in zip(X,Y)) / len(X) # covariance between X and Y\n",
    "    \n",
    "        stdevX = (sum((a - mX)**2 for a in X)/len(X))**0.5 # standard deviation of X and Y\n",
    "        stdevY = (sum((a - mY)**2 for a in Y)/len(Y))**0.5\n",
    "    \n",
    "        return round(cov/(stdevX*stdevY),3) # pearson correlation calculation\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def calculate_days(date1,date2):\n",
    "    return pd.Timedelta((date2 - date1)).days\n",
    "\n",
    "def find_bestPearson(x,y,days_x,days_y,cp,nb_days,max_cp): # param : x list and y list to find best Pearson correlation, days which corresponds to x and y lists, and cp the initial pearson found. nb_days is the INOUT parameter, which is initialized at 0 in first call, and stands for the gap of days between chinese and selected EU markets\n",
    "    if len(x)==0 or len(y)==0:\n",
    "        return nb_days\n",
    "    else:\n",
    "        if days_x[0] == days_y[0]:\n",
    "            y = y[1:] # tail of EU prices\n",
    "            new_cp = abs(pearson(x,y))\n",
    "            head, *tail = days_y\n",
    "            if new_cp > cp:\n",
    "                head2, *tail2 = tail\n",
    "                return find_bestPearson(x,y,days_x,tail,new_cp,nb_days+calculate_days(head[0],head2[0]),new_cp)\n",
    "            else:\n",
    "                return find_bestPearson(x,y,days_x,tail,new_cp,nb_days,cp)\n",
    "        else:\n",
    "            while days_x[0] < days_y[0]: # cn data always begins before or at the same time as EU data\n",
    "                head, *tail = days_x\n",
    "                x = x[1:]\n",
    "                days_x = tail\n",
    "            new_cp = abs(pearson(x,y))\n",
    "            if new_cp > cp:\n",
    "                return find_bestPearson(x,y,days_x,days_y,new_cp,nb_days,new_cp)\n",
    "            else:\n",
    "                return find_bestPearson(x,y,days_x,days_y,new_cp,nb_days,cp)\n",
    "\n",
    "def apprendre_skin(filename):\n",
    "    print(filename + \" processing...\")\n",
    "    dataset = pd.read_csv(filename)\n",
    "    print(dataset)\n",
    "    try:\n",
    "\n",
    "        dataset[\"prix\"] = dataset[\"prix\"].astype(float)\n",
    "        dataset[\"date\"] = pd.to_datetime(dataset[\"date\"])\n",
    "\n",
    "        # analyses sommaires\n",
    "        print(dataset.shape)\n",
    "\n",
    "        # on consulte les types des données:\n",
    "        print(dataset.dtypes)\n",
    "\n",
    "        # aperçu des stats de chaque colonne\n",
    "        pd.set_option('precision', 3)\n",
    "        print(dataset.describe())\n",
    "    \n",
    "        # histograms\n",
    "        dataset.hist(bins=10,figsize=(15,10),grid=False)\n",
    "        plt.show()\n",
    "\n",
    "        # Setting X and Y axis\n",
    "        x = dataset['date'].values\n",
    "        x = x.reshape(-1,1)\n",
    "        y = dataset['prix'].values\n",
    "    \n",
    "        plt.title(\"Variation des prix de l'item en fonction des dates\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Prix\")\n",
    "        plt.plot(x,y)\n",
    "        plt.show()\n",
    "    \n",
    "        # Train / Validation / Test split (60%/20%/20%)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=7)\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=8) # 0.25 * 0.8 = 0.2\n",
    "\n",
    "        alpha_values = np.linspace(dataset['prix'].min(), dataset['prix'].max()+1, len(dataset.index)) # tous les datasets font max 180 lignes (= 6 mois de données) donc on peut se permettre une telle simplification\n",
    "    \n",
    "    \n",
    "        # input standardization\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        scores = []\n",
    "        for alpha in alpha_values:\n",
    "            # alpha est fixé (comme mu=mu0)\n",
    "            monModele = sklearn.linear_model.Ridge(alpha=alpha)\n",
    "    \n",
    "            # je converge theta vers theta*\n",
    "            monModele.fit(X_train, Y_train)\n",
    "    \n",
    "            score = monModele.score(X_val, Y_val)\n",
    "            scores.append(score)\n",
    "\n",
    "        alpha_etoile = np.argmax(np.array(scores))\n",
    "\n",
    "        # Fitting with fixed hyper-parameter\n",
    "        monModele = sklearn.linear_model.Ridge(alpha=alpha_etoile)\n",
    "        monModele.fit(X_train, Y_train)\n",
    "        print(\"Comparaison des scores entre training, validation et test : \", monModele.score(X_train, Y_train), monModele.score(X_val, Y_val), monModele.score(X_test, Y_test))\n",
    "    \n",
    "        # Predictions\n",
    "        Y_train_pred = monModele.predict(X_train)\n",
    "        print(\"train error\", sklearn.metrics.mean_squared_error(Y_train_pred, Y_train))\n",
    "\n",
    "        Y_test_pred = monModele.predict(X_test)\n",
    "        mse = sklearn.metrics.mean_squared_error(Y_test_pred, Y_test)\n",
    "        print(\"test error\", mse)\n",
    "    \n",
    "        # R^2 calculation\n",
    "        print(\"R^2 (best possible value is 1.0) :\", sklearn.metrics.r2_score(Y_test,Y_test_pred))\n",
    "    \n",
    "        # MAE calculation\n",
    "        mae = sklearn.metrics.mean_absolute_error(Y_test,Y_test_pred)\n",
    "        print(\"The mean absolute error is: {:.2f}\".format(mae))\n",
    "    \n",
    "        # ----- Cross-validation -----\n",
    "        # kfold_validation=KFold(5)\n",
    "\n",
    "        # results=cross_val_score(monModele,x,y,cv=kfold_validation)\n",
    "        # print(results)\n",
    "        # print(np.mean(results))\n",
    "\n",
    "    \n",
    "        plt.scatter(x=range(0,Y_test.size), y=Y_test, marker='x', label='Actual')\n",
    "        plt.scatter(x=range(0,Y_test_pred.size) , y=Y_test_pred, marker='+', label='Predicted')\n",
    "        plt.xlabel('Price index in dataset')\n",
    "        plt.ylabel('Price to guess/guessed')\n",
    "        plt.legend()\n",
    "        plt.title(\"Actual and predicted values\")\n",
    "        plt.show()\n",
    "    \n",
    "        # Visualization with MAE on test values\n",
    "        plt.scatter(X_train, Y_train, marker='x', label='train')\n",
    "        plt.scatter(X_test, Y_test, marker='+', label='test')\n",
    "    \n",
    "        plt.legend()\n",
    "        plt.title(\"Linear regression with MAE visualization on test values\")\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Prix')\n",
    "        plt.errorbar(X_test,Y_test_pred,mae)\n",
    "        plt.plot(X_test, Y_test_pred, color = \"black\")\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "        # Visualization with MSE on test values\n",
    "        plt.scatter(X_train, Y_train, marker='x', label='train')\n",
    "        plt.scatter(X_test, Y_test, marker='+', label='test')\n",
    "    \n",
    "        plt.legend()\n",
    "        plt.title(\"Linear regression with MSE visualization on test values\")\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Prix')\n",
    "        plt.errorbar(X_test,Y_test_pred,mse)\n",
    "        plt.plot(X_test, Y_test_pred, color = \"black\")\n",
    "        plt.show()\n",
    "    \n",
    "        return x,y\n",
    "    except:\n",
    "        print(\"Il n'y a aucun prix pour\", filename)\n",
    "        return np.empty(0),np.empty(0,dtype='datetime64[ns]')\n",
    "\n",
    "os.rmdir('prices/.ipynb_checkpoints')\n",
    "dirct_cn = os.listdir('prices')\n",
    "dirct_cn.sort()\n",
    "\n",
    "os.rmdir('merged_prices/.ipynb_checkpoints')\n",
    "dirct_eu = os.listdir('merged_prices')\n",
    "dirct_eu.sort()\n",
    "\n",
    "for csv_cn in dirct_cn:\n",
    "    x_cn,y_cn = apprendre_skin(\"prices/\"+csv_cn)\n",
    "    x_eu,y_eu = apprendre_skin(\"merged_prices/\"+dirct_eu[0])\n",
    "    dirct_eu = dirct_eu[1:]\n",
    "    \n",
    "    corr = pearson(y_cn,y_eu) # pearson correlation\n",
    "    \n",
    "    print(\"Corrélation de Pearson entre le marché chinois et le marché EU pour\", csv_cn, \":\", corr)\n",
    "#    nb_days = find_bestPearson(y_cn.tolist(),y_eu.tolist(),x_cn,x_eu,result_eu,0,0)\n",
    "    \n",
    "#    print(\"Chinese prices are in advance of\", nb_days, \"EU prices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61013923-ecfc-4f90-9e5f-5485db9d321b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed367603-ee3a-4509-985e-5aafb66f644a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455bb7bf-1940-44ad-809f-69a6ccf7620e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9703ef-8628-4e04-a70f-682d2289d0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b366b5a-0376-4c58-82b5-9a7435023b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63594238-5c88-4f75-95c0-91b72cfafdec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e0258-5623-421f-b7cc-850fd6631e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dacf74-cd52-4c0c-a88e-7b0124c601e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb59f9f-3f72-41db-9638-0432b88f4805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975fa80-43d2-4ae7-a3d0-331a732a9eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36912f59-ebd4-4d8b-b8b4-724ddfdc2e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7733fb3-58d4-44dc-9af3-0168a2579a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d80e05-7db4-4cb3-afc6-5ca3045b8d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
